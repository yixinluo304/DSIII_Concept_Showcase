---
title: "EDA and Text Cleaning"
format:
  html:
    code-fold: true
jupyter: python3
---

Yixin Luo

## EDA

```{python}
import torch
```

```{python}
import pandas as pd
import numpy as np
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from collections import Counter
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score

## Load data
df = pd.read_csv('~/Downloads/tripadvisor_hotel_reviews.csv')


## distribution of ratings
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Rating', palette='viridis')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()
```

#### Distribution of Ratings: The bar chart displays the frequency of ratings from 1 to 5, highlighting that the majority of users gave a rating of 5.

```{python}
## Check the length of reviews
df["word_length"] = df["Review"].apply(len)

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="word_length", hue="Rating", multiple="stack", palette="bright")
plt.title('Distribution of Text Lengths by Class', fontsize=16)
plt.xlabel('Text Length', fontsize=14)
plt.ylabel('Frequency')
plt.show()
```

#### Distribution of Text Lengths by Class: The histogram shows the distribution of review text lengths, segmented by rating class, revealing that most reviews are short across all ratings.

```{python}
from collections import Counter
import pandas as pd
import re

# Step 1: Preprocess the text
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = re.sub(r'\d+', '', text)  # Remove numbers
    return text

df['cleaned_review'] = df['Review'].apply(clean_text)

# Step 2: Tokenize the text and count words
all_words = ' '.join(df['cleaned_review']).split()  # Combine all reviews and split into words
word_counts = Counter(all_words)  # Count word frequencies

# Step 3: Get the most common words
most_common_words = word_counts.most_common(20)  # Top 20 most common words
print("Most Common Words:", most_common_words)

# Convert to a DataFrame for better readability
most_common_df = pd.DataFrame(most_common_words, columns=['Word', 'Frequency'])
print(most_common_df)

# Horizontal visualization
plt.figure(figsize=(10, 6))
plt.barh(most_common_df['Word'], most_common_df['Frequency'], color='skyblue')
plt.title('Top 20 Most Common Words in Reviews', fontsize=16)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Words', fontsize=12)
plt.gca().invert_yaxis()  # Invert y-axis to show highest frequency on top
plt.tight_layout()
plt.show()
```

#### Top 20 Most Common Words in Reviews: The bar chart identifies the most frequently used words in hotel reviews, with "hotel" and "room" being the most common, indicating key topics of discussion.

---------------------------------------------------
## Text Cleaning

### remove the big comments

```{python}
# remove the big comments
df = df[df['word_length'] <= 3000]

df["word_length"] = df["Review"].apply(len)

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="word_length", hue="Rating", multiple="stack", palette="bright")
plt.title('Distribution of Text Lengths by Class', fontsize=16)
plt.xlabel('Text Length', fontsize=14)
plt.ylabel('Frequency')
plt.show()
```

```{python}
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk


# Text cleaning function
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra whitespace
    return text

# Apply text cleaning
df.loc[:, 'cleaned_review'] = df['Review'].apply(clean_text)
```